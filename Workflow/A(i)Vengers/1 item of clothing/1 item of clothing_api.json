{
  "4": {
    "inputs": {
      "ckpt_name": "realismEngineSDXL_v30VAE.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "15": {
    "inputs": {
      "resolution": 1024,
      "image": [
        "54",
        0
      ]
    },
    "class_type": "OneFormer-COCO-SemSegPreprocessor",
    "_meta": {
      "title": "OneFormer COCO Segmentor"
    }
  },
  "16": {
    "inputs": {
      "image": "$16-0",
      "block": false,
      "images": [
        "15",
        0
      ]
    },
    "class_type": "PreviewBridge",
    "_meta": {
      "title": "Preview Bridge (Image)"
    }
  },
  "18": {
    "inputs": {
      "channel": "red",
      "image": [
        "15",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "Convert Image to Mask"
    }
  },
  "19": {
    "inputs": {
      "weight": 0.5,
      "weight_faceidv2": 1.5,
      "weight_type": "linear",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "model": [
        "4",
        0
      ],
      "ipadapter": [
        "20",
        0
      ],
      "image": [
        "54",
        0
      ],
      "attn_mask": [
        "18",
        0
      ],
      "clip_vision": [
        "21",
        0
      ],
      "insightface": [
        "22",
        0
      ]
    },
    "class_type": "IPAdapterFaceID",
    "_meta": {
      "title": "IPAdapter FaceID"
    }
  },
  "20": {
    "inputs": {
      "ipadapter_file": "ip-adapter-faceid-plusv2_sdxl.bin"
    },
    "class_type": "IPAdapterModelLoader",
    "_meta": {
      "title": "IPAdapter Model Loader"
    }
  },
  "21": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "22": {
    "inputs": {
      "provider": "CPU",
      "model_name": "buffalo_l"
    },
    "class_type": "IPAdapterInsightFaceLoader",
    "_meta": {
      "title": "IPAdapter InsightFace Loader"
    }
  },
  "25": {
    "inputs": {
      "ipadapter_file": "ip-adapter-plus-face_sdxl_vit-h.safetensors"
    },
    "class_type": "IPAdapterModelLoader",
    "_meta": {
      "title": "IPAdapter Model Loader"
    }
  },
  "26": {
    "inputs": {
      "text": [
        "122",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "27": {
    "inputs": {
      "text": [
        "122",
        1
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "28": {
    "inputs": {
      "seed": 247586671246318,
      "steps": 35,
      "cfg": 8,
      "sampler_name": "dpmpp_2m",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "51",
        0
      ],
      "positive": [
        "26",
        0
      ],
      "negative": [
        "27",
        0
      ],
      "latent_image": [
        "29",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "29": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "30": {
    "inputs": {
      "samples": [
        "28",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "31": {
    "inputs": {
      "image": "$31-0",
      "block": true,
      "images": [
        "30",
        0
      ]
    },
    "class_type": "PreviewBridge",
    "_meta": {
      "title": "Preview Bridge (Image)"
    }
  },
  "45": {
    "inputs": {
      "weight": 0.3,
      "weight_type": "linear",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "model": [
        "19",
        0
      ],
      "ipadapter": [
        "25",
        0
      ],
      "image": [
        "54",
        0
      ],
      "attn_mask": [
        "18",
        0
      ],
      "clip_vision": [
        "21",
        0
      ]
    },
    "class_type": "IPAdapterAdvanced",
    "_meta": {
      "title": "IPAdapter Advanced"
    }
  },
  "46": {
    "inputs": {
      "image": "top_dress_3.jpg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "47": {
    "inputs": {
      "resolution": 1024,
      "image": [
        "46",
        0
      ]
    },
    "class_type": "UniFormer-SemSegPreprocessor",
    "_meta": {
      "title": "UniFormer Segmentor"
    }
  },
  "48": {
    "inputs": {
      "channel": "green",
      "image": [
        "47",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "Convert Image to Mask"
    }
  },
  "49": {
    "inputs": {
      "ipadapter_file": "ip-adapter-plus_sdxl_vit-h.safetensors"
    },
    "class_type": "IPAdapterModelLoader",
    "_meta": {
      "title": "IPAdapter Model Loader"
    }
  },
  "51": {
    "inputs": {
      "weight": 0.5,
      "weight_type": "linear",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "model": [
        "45",
        0
      ],
      "ipadapter": [
        "49",
        0
      ],
      "image": [
        "46",
        0
      ],
      "attn_mask": [
        "48",
        0
      ],
      "clip_vision": [
        "21",
        0
      ]
    },
    "class_type": "IPAdapterAdvanced",
    "_meta": {
      "title": "IPAdapter Advanced"
    }
  },
  "52": {
    "inputs": {
      "images": [
        "47",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "54": {
    "inputs": {
      "image": "835e0f0b83da64eb3ec31fd9944ef00d.jpg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "109": {
    "inputs": {
      "ckpt_name": "Deliberate_v5.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "110": {
    "inputs": {
      "text": "photo studio background",
      "clip": [
        "109",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "111": {
    "inputs": {
      "seed": 355855037685439,
      "steps": 35,
      "cfg": 8,
      "sampler_name": "dpmpp_2m",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "109",
        0
      ],
      "positive": [
        "110",
        0
      ],
      "negative": [
        "118",
        0
      ],
      "latent_image": [
        "116",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "112": {
    "inputs": {
      "samples": [
        "111",
        0
      ],
      "vae": [
        "109",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "113": {
    "inputs": {
      "transparency": true,
      "model": "u2net",
      "post_processing": false,
      "only_mask": false,
      "alpha_matting": false,
      "alpha_matting_foreground_threshold": 240,
      "alpha_matting_background_threshold": 10,
      "alpha_matting_erode_size": 10,
      "background_color": "none",
      "images": [
        "30",
        0
      ]
    },
    "class_type": "Image Rembg (Remove Background)",
    "_meta": {
      "title": "Image Rembg (Remove Background)"
    }
  },
  "114": {
    "inputs": {
      "images": [
        "113",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "115": {
    "inputs": {
      "method": "default",
      "images": [
        "113",
        0
      ]
    },
    "class_type": "AlphaChanelAsMask",
    "_meta": {
      "title": "AlphaChanelAsMask"
    }
  },
  "116": {
    "inputs": {
      "grow_mask_by": 6,
      "pixels": [
        "30",
        0
      ],
      "vae": [
        "109",
        2
      ],
      "mask": [
        "115",
        0
      ]
    },
    "class_type": "VAEEncodeForInpaint",
    "_meta": {
      "title": "VAE Encode (for Inpainting)"
    }
  },
  "117": {
    "inputs": {
      "images": [
        "112",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "118": {
    "inputs": {
      "text": "(worst quality, low quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitsch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D, 3D Game, 3D Game Scene, 3D Character:1.1), acne",
      "clip": [
        "109",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "119": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "112",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "121": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "112",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "122": {
    "inputs": {
      "style1": "tops_dress_3",
      "style2": "No_Style",
      "style3": "No_Style",
      "style4": "No_Style"
    },
    "class_type": "Prompt Multiple Styles Selector",
    "_meta": {
      "title": "Prompt Multiple Styles Selector"
    }
  },
  "126": {
    "inputs": {
      "upscale_by": 2,
      "seed": 115540336083059,
      "steps": 6,
      "cfg": 1,
      "sampler_name": "dpmpp_sde",
      "scheduler": "normal",
      "denoise": 0.2,
      "mode_type": "Linear",
      "tile_width": 1024,
      "tile_height": 1024,
      "mask_blur": 8,
      "tile_padding": 32,
      "seam_fix_mode": "None",
      "seam_fix_denoise": 1,
      "seam_fix_width": 64,
      "seam_fix_mask_blur": 8,
      "seam_fix_padding": 16,
      "force_uniform_tiles": true,
      "tiled_decode": false,
      "image": [
        "112",
        0
      ],
      "model": [
        "51",
        0
      ],
      "positive": [
        "26",
        0
      ],
      "negative": [
        "27",
        0
      ],
      "vae": [
        "4",
        2
      ],
      "upscale_model": [
        "127",
        0
      ]
    },
    "class_type": "HD UltimateSDUpscale",
    "_meta": {
      "title": "HD Ultimate SD Upscale"
    }
  },
  "127": {
    "inputs": {
      "model_name": "4x-UltraSharp.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "137": {
    "inputs": {
      "images": [
        "126",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "138": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "126",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  }
}